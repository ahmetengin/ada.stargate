
# ğŸ Ada Backend: Python Enterprise Stack Setup

**Goal:** Migrate from the Frontend Simulation to a "Big 3" Production Backend.

## 1. Core Technology Stack

| Component | Library | Purpose |
| :--- | :--- | :--- |
| **API Framework** | `FastAPI` | High-performance Async I/O for serving the Orchestrator. |
| **Agent Runtime** | `LangGraph` | Stateful orchestration, cycles, and persistence (The Brain). |
| **MCP Server** | `FastMCP` | Building the Expert Nodes (`ada.finance`, `ada.legal`). |
| **Validation** | `Pydantic AI` | "Zero Error" structured outputs and tool definitions. |
| **Memory** | `Redis` | Hot storage for conversation state and Event Bus. |
| **Vector DB** | `Qdrant` | RAG storage for `ada.legal` documents. |
| **Database** | `PostgreSQL` | Persistent entity storage (Invoices, Vessels). |

## 2. Folder Structure (The "Big 3" Pattern)

This structure enforces separation of concerns.

```text
backend/
â”œâ”€â”€ main.py                  # FastAPI Entry Point (Webhooks & Chat Endpoint)
â”œâ”€â”€ config.py                # Environment Variables
â”‚
â”œâ”€â”€ orchestrator/            # LEVEL 1: THE ROUTER (LangGraph)
â”‚   â”œâ”€â”€ graph.py             # The State Graph definition
â”‚   â”œâ”€â”€ state.py             # Pydantic models for Graph State
â”‚   â””â”€â”€ router.py            # Logic to select the next Expert
â”‚
â”œâ”€â”€ nodes/                   # LEVEL 2: THE EXPERTS (MCP Servers)
â”‚   â”œâ”€â”€ finance/
â”‚   â”‚   â”œâ”€â”€ server.py        # FastMCP Server
â”‚   â”‚   â””â”€â”€ tools.py         # Pydantic AI Tool Definitions
â”‚   â”œâ”€â”€ legal/
â”‚   â”‚   â”œâ”€â”€ server.py
â”‚   â”‚   â””â”€â”€ rag_engine.py    # Qdrant Integration
â”‚   â””â”€â”€ marina/
â”‚       â””â”€â”€ server.py
â”‚
â”œâ”€â”€ workers/                 # LEVEL 3: THE HANDS (Pure Logic)
â”‚   â”œâ”€â”€ calculators.py       # Pure Python math (Penalty calc, Tax calc)
â”‚   â””â”€â”€ scrapers.py          # Kpler/MarineTraffic scrapers
â”‚
â””â”€â”€ hooks/                   # OBSERVABILITY
    â”œâ”€â”€ emitter.py           # Redis Publisher
    â””â”€â”€ middleware.py        # Automatic tracing for requests
```

## 3. Getting Started

### A. Initialize Project
```bash
mkdir backend
cd backend
python3 -m venv venv
source venv/bin/activate
```

### B. Install Dependencies
Create `requirements.txt`:
```text
fastapi
uvicorn
langgraph
langchain-google-genai
fastmcp
pydantic-ai
redis
qdrant-client
asyncpg
```

```bash
pip install -r requirements.txt
```

### C. Run the Event Bus (Redis)
```bash
docker run -d -p 6379:6379 redis
```

### D. Start the Brain
```bash
uvicorn main:app --reload
```

## 4. The "Zero Error" Workflow

1.  **Define Types:** Create a Pydantic model for the expected output (e.g., `InvoiceSchema`).
2.  **Write the Worker:** Write a pure Python function `calculate_invoice` that passes unit tests.
3.  **Wrap in MCP:** Expose this function via `FastMCP` in `nodes/finance`.
4.  **Orchestrate:** Add a node in `LangGraph` that calls this MCP tool.
5.  **Validate:** Use `Pydantic AI` to ensure the LLM's input to the tool matches the schema strictly.
